import json
import os
import pickle

import dask.array as da
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import zarr
from dask.diagnostics import ProgressBar
from multiview_stitcher import fusion, io, msi_utils, ngff_utils, registration
from multiview_stitcher import spatial_image_utils as si_utils
from multiview_stitcher import vis_utils
from skimage.filters import threshold_otsu

matplotlib.use("agg")


def get_background_threshold(tile_means):

    from scipy.signal import find_peaks

    # Compute histogram
    hist, bin_edges = np.histogram(tile_means, bins=100)

    # Find valleys (peaks in negative histogram)
    valley_indices, _ = find_peaks(-hist)

    # Get the threshold as the bin edge corresponding to the first valley
    if valley_indices.size > 0:
        valley_threshold = bin_edges[valley_indices[0]]
    else:
        valley_threshold = None
        print("No valley detected in histogram.")

    # Plot the histogram and mark the valley threshold
    #    plt.figure(figsize=(10, 6))
    #    plt.hist(data, bins=100, edgecolor='black', alpha=0.7)
    #    if valley_threshold is not None:
    #        plt.axvline(valley_threshold, color='red', linestyle='--', label=f'Valley Threshold â‰ˆ {valley_threshold:.2f}')
    #        plt.legend()
    #    plt.title('Histogram with Valley Threshold')
    #    plt.xlabel('Value')
    #    plt.ylabel('Frequency')
    #    plt.grid(True)
    #    plt.show()
    return valley_threshold


in_zarr = snakemake.input.zarr

darr = da.from_zarr(in_zarr)

(n_tiles, n_chans, n_z, n_x, n_y) = darr.shape

# read metadata json
with open(snakemake.input.metadata_json) as fp:
    metadata = json.load(fp)


msims = []
zarr_paths = []

curr_transform_key = "affine_metadata"
new_transform_key = "affine_registered"


channel = metadata["channels"][snakemake.params.reg_channel_index]

# get tile means for calculating whether a tile contains the sample or not


# Select the relevant channel across all tiles
# Resulting shape: (num_tiles, z, y, x)
selected = darr[:, snakemake.params.reg_channel_index, :, :, :]

# Compute mean across spatial dimensions per tile
# Resulting shape: (num_tiles,)
print("calculating means per tile")
with ProgressBar():
    tile_means = selected.mean(axis=(1, 2, 3)).compute()

background_threshold = get_background_threshold(tile_means)
print(f"background threshold: {background_threshold}")

# Determine sample presence based on threshold
contain_sample = list(tile_means > background_threshold)

# Optional: print tile means
for i_tile, mean_val in zip(metadata["chunks"], tile_means):
    print(f"{i_tile}, mean={mean_val}")


for i_tile in metadata["chunks"]:

    key = f"tile-{i_tile}_chan-{channel}_z-0000"

    # read tile image
    im_data = da.squeeze(darr[i_tile, :, :, :, :])

    print(im_data.shape)
    sim = si_utils.get_sim_from_array(
        im_data,
        dims=["c", "z", "y", "x"],
        scale={
            "z": metadata["physical_size_z"],
            "y": metadata["physical_size_y"],
            "x": metadata["physical_size_x"],
        },
        translation={
            "z": -metadata["lookup_tile_offset_z"][key],
            "y": -metadata["lookup_tile_offset_y"][key],
            "x": metadata["lookup_tile_offset_x"][key],
        },
        c_coords=snakemake.params.channels,
        transform_key=io.METADATA_TRANSFORM_KEY,
    )

    # for next steps, we read things back as msim
    msim = msi_utils.get_msim_from_sim(sim)

    msims.append(msim)


# exclude tiles containing only background from registration
print("performing stitching registration")
with ProgressBar():
    reg_result = registration.register(
        [msim for i, msim in enumerate(msims) if contain_sample[i]],
        reg_channel_index=snakemake.params.reg_channel_index,
        transform_key=curr_transform_key,
        new_transform_key=new_transform_key,
        pre_registration_pruning_method="keep_axis_aligned",
        post_registration_do_quality_filter=True,
        post_registration_quality_threshold=0.6,
        scheduler="threads",
        return_dict=True,
        **snakemake.params.registration_opts,
    )


# Extract each affine and save to disk as a single .npz file
affines = {}
for imsim, msim in enumerate(msims):
    if contain_sample[imsim]:
        affine = np.array(
            msi_utils.get_transform_from_msim(msim, transform_key=new_transform_key)[0]
        )
    else:
        affine = np.eye(4)

    affines[f"tile_{imsim}"] = affine
    print(f"tile index {imsim}\n", affine)

np.savez(snakemake.output.affines, **affines)
print("Saved affines to registered_affines.npz")


# Save the entire registration result dictionary
with open(snakemake.output.reg_result_pkl, "wb") as f:
    pickle.dump(reg_result, f)

print("Saved full registration result to Pickle")
